{"meta":{"title":"AI for Science","subtitle":"","description":"my ai learning experience","author":"Dino","url":"http://zhangwenxiang.com","root":"/"},"pages":[{"title":"about","date":"2023-08-29T03:27:13.000Z","updated":"2023-09-01T07:25:40.988Z","comments":true,"path":"about/index.html","permalink":"http://zhangwenxiang.com/about/index.html","excerpt":"","text":"ABOUT ME"},{"title":"categories","date":"2023-09-01T07:21:00.000Z","updated":"2023-09-01T07:23:53.836Z","comments":true,"path":"categories/index.html","permalink":"http://zhangwenxiang.com/categories/index.html","excerpt":"","text":""},{"title":"link","date":"2023-09-04T02:29:30.000Z","updated":"2023-09-04T02:30:19.096Z","comments":true,"path":"link/index.html","permalink":"http://zhangwenxiang.com/link/index.html","excerpt":"","text":""},{"title":"tags","date":"2023-09-01T07:19:58.000Z","updated":"2023-09-01T07:20:42.492Z","comments":true,"path":"tags/index.html","permalink":"http://zhangwenxiang.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Ubuntu安装问题汇总","slug":"Ubuntu安装问题汇总","date":"2023-10-16T12:53:15.000Z","updated":"2023-10-17T07:28:20.975Z","comments":true,"path":"2023/10/16/Ubuntu安装问题汇总/","link":"","permalink":"http://zhangwenxiang.com/2023/10/16/Ubuntu%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/","excerpt":"","text":"系统安装在官网下载Ubuntu镜像：Ubuntu 20.04.1 LTS (Focal Fossa)，选择Desktop Image版本，得到.iso的镜像文件。 黑屏无法进入安装界面123sudo gedit /etc/default/grubGRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash nomodeset“ sudo update-grub 选中引导界面，选中ubuntu，依据提示按e 1rw quiet splash nomodeset 锁定显卡自动更新关闭nouveau 1sudo vim /etc/modprobe.d/blacklist.conf 文件最后插入： 12blacklist nouveauoptions nouveau modeset=0 更新 1sudo update-initramfs -u GRUB1vim /etc/default/grub 找到 GRUB_HIDDEN_TIMEOUT&#x3D;0 这行，使用#注释掉，变成 #GRUB_HIDDEN_TIMEOUT&#x3D;0保存退出 1sudo update-grub 若不行，重装123sudo update-grub sudo grub-install /dev/sda sudo reboot #重启 &#x2F;etc&#x2F;default&#x2F;grub文件介绍GRUB_TIMEOUT&#x3D;10（默认是为10秒的）意思是等待10秒钟，设置为负数为一直等待操作启动的时候就会显示grub菜单了，如果10秒内不选择，则会自动进入系统进入grub快捷键shift 配置国内的源1cp /etc/apt/sources.list /etc/apt/sources.list.bak 1sudo vim /etc/apt/sources.list deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse 123sudo apt updatesudo apt upgrade 安装python &amp; pip12sudo apt install python3sudo apt install python3-pip 1sudo apt install ssh 安装Cuda1. 选择对应版本，下载[https://developer.nvidia.com/cuda-12-0-1-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=22.04&amp;target_type=runfile_local] 2. 按照提示安装，若提示“Existing package manager installation of the driver found. It is strongly ”，选择continue，去掉“Driver” 3. 设置环境变量 nano ~/.bashrc 文件最后加入以下语句： export CUDA_HOME=/usr/local/cuda-12.0 export LD_LIBRARY_PATH=$&#123;CUDA_HOME&#125;/lib64 export PATH=$&#123;CUDA_HOME&#125;/bin:$&#123;PATH&#125; 使文件生效 source ~/.bashrc 4. 验证安装 nvcc -V 安装Anaconda1. wget https://repo.anaconda.com/archive/Anaconda3-2023.03-Linux-x86_64.sh 2. bash Anaconda3-2023.03-Linux-x86_64.sh 3. nano ~/.bashrc 4. 末尾添加： 1. export PATH=&quot;~/anaconda3/bin&quot;:$PATH 2. source ~/anaconda3/bin/activate 5. source ~/.bashrc 6. 进入base环境 创建新环境1. conda create -n pytorch python=3.10.9 2. conda info --envs 3. conda activate pytorch 安装pytorch1. conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia 2. 验证GPU 1. &gt;&gt;&gt; import torch 2. &gt;&gt;&gt; torch.cuda.is_available() 3. &gt;&gt;&gt; from torch.backends import cudnn 4. &gt;&gt;&gt; cudnn.is_available()","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://zhangwenxiang.com/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://zhangwenxiang.com/tags/ubuntu/"}]},{"title":"深度学习数据集","slug":"深度学习数据集","date":"2023-10-11T03:35:27.000Z","updated":"2023-10-11T03:49:11.952Z","comments":true,"path":"2023/10/11/深度学习数据集/","link":"","permalink":"http://zhangwenxiang.com/2023/10/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E9%9B%86/","excerpt":"","text":"小目标检测、图像分类、图像识别宠物图像数据集数据集下载地址：http://m6z.cn/5TAgdC一个包含 37 个类别的宠物数据集，每个类别大约有 200 张图像。这些图像在比例、姿势和照明方面有很大的变化。所有图像都有相关的品种、头部 ROI 和像素级三元图分割的地面实况注释。 街景门牌号 (SVHN) 数据集数据集下载地址：http://m6z.cn/5ExMWbSVHN 是一个真实世界的图像数据集，用于开发机器学习和对象识别算法，对数据预处理和格式化的要求最低。它可以被视为与MNIST风格相似（例如，图像是经过裁剪的小数字），但包含一个数量级的更多标记数据（超过 600,000 个数字图像），并且来自一个更难、未解决的现实世界问题（识别自然场景图像中的数字和数字）。SVHN 是从谷歌街景图像中的门牌号获得的。 3D MNIST 数字识别图像数据数据集下载地址：http://m6z.cn/5SUfEd该数据集的目的是提供一种简单的方法来开始处理 3D 计算机视觉问题，例如 3D 形状识别。 文档影印和内容数据数据集下载地址：http://m6z.cn/6nF67SMediaTeam Oulu Document 数据集是一个文档扫描图像和文档内容数据集，包含 500篇 1975年之前的文档信息。 猫咪数据集数据集下载地址：http://m6z.cn/5TAgbwCAT 数据集包括超过 9,000 张猫图像。对于每张图像，猫的头部都有九个点的注释，眼睛两个，嘴巴一个，耳朵六个。 CBCL 街道场景数据数据集下载地址：http://m6z.cn/5TAgeAStreetScenes Challenge Framework 是用于对象检测的图像、注释、软件和性能测量的集合。每张图像都是从马萨诸塞州波士顿及其周边地区的 DSC-F717 相机拍摄的。然后用围绕 9 个对象类别的每个示例的多边形手动标记每个图像，包括 [汽车、行人、自行车、建筑物、树木、天空、道路、人行道和商店]。这些图像的标记是在仔细检查下完成的，以确保对象总是以相同的方式标记，关于遮挡和其他常见的图像变换。 小目标检测数据集数据集下载地址：http://m6z.cn/616t6R从Internet（例如YouTube或Google）上的图像&#x2F;视频收集的四个小物体数据集，包括4种类型的图像，可用于小物体目标检测的研究。数据集包含四类：fly：飞行数据集，包含600个视频帧，平均每帧86±39个物体（648×72 @ 30 fps）。32张图像用于训练（1：6：187），50张图像用于测试（301：6：600）。honeybee：蜜蜂数据集，包含118张图像，每张图像平均有28±6个蜜蜂（640×480）。数据集被平均分配用于训练和测试集。仅前32张图像用于训练。seagull：海鸥数据集，包含三个高分辨率图像（624×964），每个图像平均有866±107个海鸥。第一张图片用于训练，其余图片用于测试。fish：鱼数据集，包含387帧视频数据，平均每帧56±9条鱼（300×410 @ 30 fps）。32张图像进行训练（1：3：94），65张图像进行测试（193：3：387）。 斯坦福狗狗数据集数据集下载地址：http://m6z.cn/6nF6kM斯坦福狗数据集包含来自世界各地的 120 种狗的图像。该数据集是使用 ImageNet 中的图像和注释构建的，用于细粒度图像分类任务。该数据集的内容：类别数：120图片数量：20,580注释：类标签、边界框 Zero-Shot Learing问题数据集提供几个最常用的Zero-Shot Learning的数据集，均为GoogleNet提取的图片特征，引用相应数据时，请注意对应作者的引用说明。 AwA:http://pan.baidu.com/s/1nvPzsXb CUB:http://pan.baidu.com/s/1nv3KCYH aPaY:http://pan.baidu.com/s/1hseSzVe SUN:http://pan.baidu.com/s/1gfAc33X ImageNet2:http://pan.baidu.com/s/1pLfZYQ","categories":[{"name":"dataset","slug":"dataset","permalink":"http://zhangwenxiang.com/categories/dataset/"}],"tags":[{"name":"deeplearning","slug":"deeplearning","permalink":"http://zhangwenxiang.com/tags/deeplearning/"},{"name":"dataset","slug":"dataset","permalink":"http://zhangwenxiang.com/tags/dataset/"}]},{"title":"What is a Convolutional Neural Network?","slug":"What-is-a-Convolutional-Neural-Network","date":"2023-10-11T01:58:05.000Z","updated":"2023-10-11T03:44:40.538Z","comments":true,"path":"2023/10/11/What-is-a-Convolutional-Neural-Network/","link":"","permalink":"http://zhangwenxiang.com/2023/10/11/What-is-a-Convolutional-Neural-Network/","excerpt":"","text":"What is a Convolutional Neural Network?(https://poloclub.github.io/cnn-explainer/#article-input) 动态展示CNN运行过程。","categories":[{"name":"CNN","slug":"CNN","permalink":"http://zhangwenxiang.com/categories/CNN/"}],"tags":[{"name":"cnn","slug":"cnn","permalink":"http://zhangwenxiang.com/tags/cnn/"},{"name":"deeplearning","slug":"deeplearning","permalink":"http://zhangwenxiang.com/tags/deeplearning/"}]},{"title":"论文阅读记录","slug":"论文阅读记录","date":"2023-09-26T01:42:40.000Z","updated":"2023-09-26T01:44:13.723Z","comments":true,"path":"2023/09/26/论文阅读记录/","link":"","permalink":"http://zhangwenxiang.com/2023/09/26/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95/","excerpt":"","text":"本文记录如何阅读文献，试图找到更好的阅读和记录方法。 1.找到目标文章","categories":[],"tags":[]},{"title":"CV 相关问题","slug":"CV相关问题","date":"2023-09-18T09:31:43.000Z","updated":"2023-09-18T09:32:42.757Z","comments":true,"path":"2023/09/18/CV相关问题/","link":"","permalink":"http://zhangwenxiang.com/2023/09/18/CV%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","excerpt":"","text":"CNN网络结构的发展","categories":[],"tags":[{"name":"cv","slug":"cv","permalink":"http://zhangwenxiang.com/tags/cv/"}]},{"title":"Transformer 相关问题","slug":"Transformer相关问题","date":"2023-09-18T09:13:14.000Z","updated":"2023-09-19T09:33:01.696Z","comments":true,"path":"2023/09/18/Transformer相关问题/","link":"","permalink":"http://zhangwenxiang.com/2023/09/18/Transformer%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","excerpt":"","text":"Transformer为什么 dot-product attention 需要被 scaled？ Attention&#x2F;Self-Attention注意力机制到底在做什么，Q&#x2F;K&#x2F;V怎么来的？一文读懂Attention注意力机制 超详细图解Self-Attention 狗都能看懂的Self-Attention讲解 详解Transformer中Self-Attention以及Multi-Head Attention Vision Transformer狗都能看懂的Vision Transformer的讲解和代码实现 Vision Transformer详解 VIT(vision transformer)模型介绍+pytorch代码炸裂解析 Vision Transformer (ViT)模型与代码实现（PyTorch） 【超详细】初学者包会的Vision Transformer（ViT）的PyTorch实现代码学习 VIDEOVIT(vision transformer)模型介绍+pytorch代码炸裂解析Transformer中Self-Attention以及Multi-Head Attention详解Attention、Transformer公式推导和矩阵变化 CODEVision Transformer and MLP-Mixer ArchitecturesWZMIAOMIAO&#x2F;deep-learning-for-image-processing 延伸阅读近两年有哪些ViT(Vision Transformer)的改进算法？基于ViT的精细化分类算法介绍","categories":[{"name":"questions","slug":"questions","permalink":"http://zhangwenxiang.com/categories/questions/"},{"name":"toturial","slug":"questions/toturial","permalink":"http://zhangwenxiang.com/categories/questions/toturial/"}],"tags":[{"name":"transformer","slug":"transformer","permalink":"http://zhangwenxiang.com/tags/transformer/"},{"name":"vit","slug":"vit","permalink":"http://zhangwenxiang.com/tags/vit/"}]},{"title":"Personalized Federated Learning 个性化联邦学习","slug":"Personalized-Federated-Learning-个性化联邦学习","date":"2023-09-15T07:57:53.000Z","updated":"2023-09-18T09:13:43.525Z","comments":true,"path":"2023/09/15/Personalized-Federated-Learning-个性化联邦学习/","link":"","permalink":"http://zhangwenxiang.com/2023/09/15/Personalized-Federated-Learning-%E4%B8%AA%E6%80%A7%E5%8C%96%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"Ref：个性化联邦学习 Towards Personalized Federated Learning","categories":[],"tags":[]},{"title":"timm","slug":"timm","date":"2023-09-15T02:54:39.000Z","updated":"2023-09-23T05:56:05.857Z","comments":true,"path":"2023/09/15/timm/","link":"","permalink":"http://zhangwenxiang.com/2023/09/15/timm/","excerpt":"","text":"timm timm install方法1. pip install timm方法2.","categories":[{"name":"tutorial","slug":"tutorial","permalink":"http://zhangwenxiang.com/categories/tutorial/"}],"tags":[{"name":"timm","slug":"timm","permalink":"http://zhangwenxiang.com/tags/timm/"},{"name":"pytorch","slug":"pytorch","permalink":"http://zhangwenxiang.com/tags/pytorch/"}]},{"title":"Vision Transformer(ViT)","slug":"Vision-Transformer-ViT","date":"2023-09-08T02:48:00.000Z","updated":"2023-09-26T01:44:49.877Z","comments":true,"path":"2023/09/08/Vision-Transformer-ViT/","link":"","permalink":"http://zhangwenxiang.com/2023/09/08/Vision-Transformer-ViT/","excerpt":"","text":"AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE[原文]（https://arxiv.org/abs/2010.11929）中文 Vision Transformer(ViT)Paper:An Image is Worth 16x16 Words: Transformers for Image Recognition at ScaleDosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., … Houlsby, N. (2020). arXiv: Computer Vision and Pattern Recognition ABSTRACTWhile the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train. Notes:什么是Transformer位置编码？ Video:Vision Transformer (ViT) 用于图片分类 使用pytorch搭建Vision Transformer(vit)模型 Reference:[1]DOSOVITSKIY A, BEYER L, KOLESNIKOV A, et al. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale[J]. arXiv: Computer Vision and Pattern Recognition,arXiv: Computer Vision and Pattern Recognition, 2020.","categories":[{"name":"article","slug":"article","permalink":"http://zhangwenxiang.com/categories/article/"}],"tags":[{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/tags/phd/"},{"name":"transformer","slug":"transformer","permalink":"http://zhangwenxiang.com/tags/transformer/"},{"name":"article","slug":"article","permalink":"http://zhangwenxiang.com/tags/article/"},{"name":"ai","slug":"ai","permalink":"http://zhangwenxiang.com/tags/ai/"},{"name":"model","slug":"model","permalink":"http://zhangwenxiang.com/tags/model/"},{"name":"cv","slug":"cv","permalink":"http://zhangwenxiang.com/tags/cv/"},{"name":"vit","slug":"vit","permalink":"http://zhangwenxiang.com/tags/vit/"}]},{"title":"向量(vector)和张量(tensor)","slug":"向量-vector-和张量-tensor","date":"2023-09-07T03:33:57.000Z","updated":"2023-09-19T09:33:36.201Z","comments":true,"path":"2023/09/07/向量-vector-和张量-tensor/","link":"","permalink":"http://zhangwenxiang.com/2023/09/07/%E5%90%91%E9%87%8F-vector-%E5%92%8C%E5%BC%A0%E9%87%8F-tensor/","excerpt":"","text":"张量是多维数组，目的是把向量、矩阵推向更高的维度。 点——标量（scalar）线——向量（vector）面——矩阵（matrix）体——张量（tensor） 向量（vector）张量（tensor）url：PyTorch中张量的使用：http://t.csdn.cn/UdkHE PyTorchshape: 张量的形状，即各维度的大小。dtype: 张量的数据类型，例如float32、int64等。device: 张量存放的设备，例如cpu或cuda。Ref:张量（tensor）图解Vit 1：Vision Transformer——图像与Transformer基础","categories":[],"tags":[]},{"title":"Attention Is All You Need","slug":"Attention-Is-All-You-Need","date":"2023-09-06T07:38:44.000Z","updated":"2023-09-08T03:32:32.462Z","comments":true,"path":"2023/09/06/Attention-Is-All-You-Need/","link":"","permalink":"http://zhangwenxiang.com/2023/09/06/Attention-Is-All-You-Need/","excerpt":"","text":"ATTENTION IS ALL YOU NEEDPaper:Notes:Video:","categories":[{"name":"article","slug":"article","permalink":"http://zhangwenxiang.com/categories/article/"}],"tags":[{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/tags/phd/"},{"name":"transformer","slug":"transformer","permalink":"http://zhangwenxiang.com/tags/transformer/"},{"name":"article","slug":"article","permalink":"http://zhangwenxiang.com/tags/article/"},{"name":"ai","slug":"ai","permalink":"http://zhangwenxiang.com/tags/ai/"},{"name":"nlp","slug":"nlp","permalink":"http://zhangwenxiang.com/tags/nlp/"},{"name":"model","slug":"model","permalink":"http://zhangwenxiang.com/tags/model/"}]},{"title":"NVIDIA驱动问题","slug":"NVIDIA驱动问题","date":"2023-09-06T01:59:02.000Z","updated":"2023-09-06T02:08:22.298Z","comments":true,"path":"2023/09/06/NVIDIA驱动问题/","link":"","permalink":"http://zhangwenxiang.com/2023/09/06/NVIDIA%E9%A9%B1%E5%8A%A8%E9%97%AE%E9%A2%98/","excerpt":"","text":"问题1：Linux服务器深度学习代码无法用GPU执行；问题2：执行命令 nvidia-smi，提示：Failed to initialize NVML: Driver&#x2F;library version mismatch原因：系统自动更新驱动分析：1.查看nvidia相关安装包信息，确认一下版本 1sudo dpkg --list | grep nvidia-* 2.查看nvidia内核版本 1cat /proc/driver/nvidia/version 3.查看安装包安装或更新情况 1cat /var/log/dpkg.log | grep nvidia 核对发现服务驱动自动更新了，所以导致显卡驱动用不了，执行不力nvidia-smi 解决办法：禁用自动更新1sudo vim /etc/apt/apt.conf.d/50unattended-upgrades 注释掉以下两行： &#x2F;&#x2F;“${distro_id}:${distro_codename}”; &#x2F;&#x2F;“${distro_id}:${distro_codename}-security”; 重启系统1sudo reboot 再次执行： 1nvidia-smi 正常： 123456789101112131415161718192021(base) dino@jarvis:~$ nvidia-smi Wed Sep 6 01:43:33 2023 +-----------------------------------------------------------------------------+| NVIDIA-SMI 525.125.06 Driver Version: 525.125.06 CUDA Version: 12.0 ||-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. || | | MIG M. ||===============================+======================+======================|| 0 NVIDIA GeForce ... Off | 00000000:01:00.0 Off | N/A || 0% 57C P0 107W / 350W | 0MiB / 12288MiB | 0% Default || | | N/A |+-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+| Processes: || GPU GI CI PID Type Process name GPU Memory || ID ID Usage ||=============================================================================|| No running processes found |+-----------------------------------------------------------------------------+ Ref: https://zhuanlan.zhihu.com/p/453955370","categories":[{"name":"tech","slug":"tech","permalink":"http://zhangwenxiang.com/categories/tech/"},{"name":"linux","slug":"tech/linux","permalink":"http://zhangwenxiang.com/categories/tech/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://zhangwenxiang.com/tags/linux/"},{"name":"nvidia","slug":"nvidia","permalink":"http://zhangwenxiang.com/tags/nvidia/"},{"name":"驱动","slug":"驱动","permalink":"http://zhangwenxiang.com/tags/%E9%A9%B1%E5%8A%A8/"},{"name":"更新","slug":"更新","permalink":"http://zhangwenxiang.com/tags/%E6%9B%B4%E6%96%B0/"}]},{"title":"Linux连接SEU校园网","slug":"Linux连接SEU校园网","date":"2023-09-06T01:47:52.000Z","updated":"2023-09-06T01:59:56.659Z","comments":true,"path":"2023/09/06/Linux连接SEU校园网/","link":"","permalink":"http://zhangwenxiang.com/2023/09/06/Linux%E8%BF%9E%E6%8E%A5SEU%E6%A0%A1%E5%9B%AD%E7%BD%91/","excerpt":"","text":"SEU校园网登录页面：w.seu.edu.cn由于Linux更新显卡驱动后需要重启，导致IP重新分配。连接校园网后需要执行Web登录页面操作，Linux命令行界面如何登录，采用curl指令操作。 Linux下执行如下命令：1$ curl &quot;w.seu.edu.cn&quot; -d &quot;a=find_mac&amp;DDDDD=学号&amp;upass=密码&amp;0MKKey=&quot;","categories":[{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/categories/phd/"},{"name":"tech","slug":"phd/tech","permalink":"http://zhangwenxiang.com/categories/phd/tech/"},{"name":"linux","slug":"phd/tech/linux","permalink":"http://zhangwenxiang.com/categories/phd/tech/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://zhangwenxiang.com/tags/linux/"},{"name":"seu","slug":"seu","permalink":"http://zhangwenxiang.com/tags/seu/"},{"name":"东南大学","slug":"东南大学","permalink":"http://zhangwenxiang.com/tags/%E4%B8%9C%E5%8D%97%E5%A4%A7%E5%AD%A6/"},{"name":"校园网","slug":"校园网","permalink":"http://zhangwenxiang.com/tags/%E6%A0%A1%E5%9B%AD%E7%BD%91/"}]},{"title":"todo list 9.4","slug":"todo-list-9-4","date":"2023-09-04T13:25:28.000Z","updated":"2023-09-04T13:36:46.406Z","comments":true,"path":"2023/09/04/todo-list-9-4/","link":"","permalink":"http://zhangwenxiang.com/2023/09/04/todo-list-9-4/","excerpt":"","text":"近两日睡眠不太好，入睡太晚。上午到实验室把宣传片完成之后便进入东张西望的状态。应该是目标没有那么具体导致的注意力不集中，因为半天或者一天的任务无法达到明确的预期，所以迟迟不能进入状态。明早把手头之前的总结内容看完，列出具体的任务清单。将任务分解后逐步完成。 接下来的具体任务：Classification by ViT","categories":[{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/categories/phd/"}],"tags":[{"name":"todo-list","slug":"todo-list","permalink":"http://zhangwenxiang.com/tags/todo-list/"}]},{"title":"宣传片","slug":"宣传片","date":"2023-09-04T02:09:30.000Z","updated":"2023-09-04T02:12:38.631Z","comments":true,"path":"2023/09/04/宣传片/","link":"","permalink":"http://zhangwenxiang.com/2023/09/04/%E5%AE%A3%E4%BC%A0%E7%89%87/","excerpt":"","text":"西藏自治区网络安全和信息化展览从收到素材大概一天半时间，我的周末啊！","categories":[{"name":"work","slug":"work","permalink":"http://zhangwenxiang.com/categories/work/"}],"tags":[{"name":"tibet","slug":"tibet","permalink":"http://zhangwenxiang.com/tags/tibet/"},{"name":"宣传片","slug":"宣传片","permalink":"http://zhangwenxiang.com/tags/%E5%AE%A3%E4%BC%A0%E7%89%87/"}]},{"title":"A New Start","slug":"A-New-Start","date":"2023-09-01T07:01:24.000Z","updated":"2023-09-01T07:40:29.277Z","comments":true,"path":"2023/09/01/A-New-Start/","link":"","permalink":"http://zhangwenxiang.com/2023/09/01/A-New-Start/","excerpt":"","text":"重新开始生涯记录，在SEU博士第三年伊始。 问题学习阅读不连续外界干扰很多，有工作的有生活的也有杂七杂八的事情。 每日总结每天结束时记录工作情况，思考并总结。","categories":[{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/categories/phd/"}],"tags":[{"name":"diary","slug":"diary","permalink":"http://zhangwenxiang.com/tags/diary/"},{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/tags/phd/"},{"name":"notes","slug":"notes","permalink":"http://zhangwenxiang.com/tags/notes/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-08-29T02:55:29.224Z","updated":"2023-08-29T02:55:29.224Z","comments":true,"path":"2023/08/29/hello-world/","link":"","permalink":"http://zhangwenxiang.com/2023/08/29/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"dataset","slug":"dataset","permalink":"http://zhangwenxiang.com/categories/dataset/"},{"name":"CNN","slug":"CNN","permalink":"http://zhangwenxiang.com/categories/CNN/"},{"name":"questions","slug":"questions","permalink":"http://zhangwenxiang.com/categories/questions/"},{"name":"toturial","slug":"questions/toturial","permalink":"http://zhangwenxiang.com/categories/questions/toturial/"},{"name":"tutorial","slug":"tutorial","permalink":"http://zhangwenxiang.com/categories/tutorial/"},{"name":"article","slug":"article","permalink":"http://zhangwenxiang.com/categories/article/"},{"name":"tech","slug":"tech","permalink":"http://zhangwenxiang.com/categories/tech/"},{"name":"linux","slug":"tech/linux","permalink":"http://zhangwenxiang.com/categories/tech/linux/"},{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/categories/phd/"},{"name":"tech","slug":"phd/tech","permalink":"http://zhangwenxiang.com/categories/phd/tech/"},{"name":"linux","slug":"phd/tech/linux","permalink":"http://zhangwenxiang.com/categories/phd/tech/linux/"},{"name":"work","slug":"work","permalink":"http://zhangwenxiang.com/categories/work/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://zhangwenxiang.com/tags/linux/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://zhangwenxiang.com/tags/ubuntu/"},{"name":"deeplearning","slug":"deeplearning","permalink":"http://zhangwenxiang.com/tags/deeplearning/"},{"name":"dataset","slug":"dataset","permalink":"http://zhangwenxiang.com/tags/dataset/"},{"name":"cnn","slug":"cnn","permalink":"http://zhangwenxiang.com/tags/cnn/"},{"name":"cv","slug":"cv","permalink":"http://zhangwenxiang.com/tags/cv/"},{"name":"transformer","slug":"transformer","permalink":"http://zhangwenxiang.com/tags/transformer/"},{"name":"vit","slug":"vit","permalink":"http://zhangwenxiang.com/tags/vit/"},{"name":"timm","slug":"timm","permalink":"http://zhangwenxiang.com/tags/timm/"},{"name":"pytorch","slug":"pytorch","permalink":"http://zhangwenxiang.com/tags/pytorch/"},{"name":"phd","slug":"phd","permalink":"http://zhangwenxiang.com/tags/phd/"},{"name":"article","slug":"article","permalink":"http://zhangwenxiang.com/tags/article/"},{"name":"ai","slug":"ai","permalink":"http://zhangwenxiang.com/tags/ai/"},{"name":"model","slug":"model","permalink":"http://zhangwenxiang.com/tags/model/"},{"name":"nlp","slug":"nlp","permalink":"http://zhangwenxiang.com/tags/nlp/"},{"name":"nvidia","slug":"nvidia","permalink":"http://zhangwenxiang.com/tags/nvidia/"},{"name":"驱动","slug":"驱动","permalink":"http://zhangwenxiang.com/tags/%E9%A9%B1%E5%8A%A8/"},{"name":"更新","slug":"更新","permalink":"http://zhangwenxiang.com/tags/%E6%9B%B4%E6%96%B0/"},{"name":"seu","slug":"seu","permalink":"http://zhangwenxiang.com/tags/seu/"},{"name":"东南大学","slug":"东南大学","permalink":"http://zhangwenxiang.com/tags/%E4%B8%9C%E5%8D%97%E5%A4%A7%E5%AD%A6/"},{"name":"校园网","slug":"校园网","permalink":"http://zhangwenxiang.com/tags/%E6%A0%A1%E5%9B%AD%E7%BD%91/"},{"name":"todo-list","slug":"todo-list","permalink":"http://zhangwenxiang.com/tags/todo-list/"},{"name":"tibet","slug":"tibet","permalink":"http://zhangwenxiang.com/tags/tibet/"},{"name":"宣传片","slug":"宣传片","permalink":"http://zhangwenxiang.com/tags/%E5%AE%A3%E4%BC%A0%E7%89%87/"},{"name":"diary","slug":"diary","permalink":"http://zhangwenxiang.com/tags/diary/"},{"name":"notes","slug":"notes","permalink":"http://zhangwenxiang.com/tags/notes/"}]}